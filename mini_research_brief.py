# -*- coding: utf-8 -*-
"""mini_research_brief.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Yv2HNOPH5JtNbVCyUb92Z5tNKnmTpsNY
"""

!pip -q install -U langchain langchain-google-genai pydantic python-dotenv

from google.colab import files
uploaded = files.upload()

!ls -la

from dotenv import load_dotenv, find_dotenv
import os

load_dotenv(find_dotenv())

key = os.getenv("GOOGLE_API_KEY")
print("API Key loaded?", bool(key))
print("Key prefix:", (key[:6] + "…") if key else None)

import sys
from typing import List
from pydantic import BaseModel, ValidationError, field_validator
from langchain_core.output_parsers import PydanticOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI

class ResearchBrief(BaseModel):
    title: str
    problem_statement: str
    key_questions: List[str]
    method_brief: List[str]
    deliverables: List[str]

    @field_validator("problem_statement")
    @classmethod
    def max_two_sentences(cls, v: str) -> str:
        count = sum(v.count(ch) for ch in ".!?")
        if count > 2:
            raise ValueError("problem_statement must be <= 2 sentences")
        return v.strip()

    @field_validator("key_questions")
    @classmethod
    def q_len(cls, v: List[str]) -> List[str]:
        if not (1 <= len(v) <= 3):
            raise ValueError("key_questions must have 1–3 items")
        return [s.strip() for s in v]

    @field_validator("method_brief")
    @classmethod
    def m_len(cls, v: List[str]) -> List[str]:
        if not (2 <= len(v) <= 4):
            raise ValueError("method_brief must have 2–4 items")
        return [s.strip() for s in v]

    @field_validator("deliverables")
    @classmethod
    def d_len(cls, v: List[str]) -> List[str]:
        if not (2 <= len(v) <= 3):
            raise ValueError("deliverables must have 2–3 items")
        return [s.strip() for s in v]

def require_api_key():
    if not os.getenv("GOOGLE_API_KEY"):
        raise RuntimeError(
            "Missing GOOGLE_API_KEY. Set it using:\n"
            "os.environ['GOOGLE_API_KEY'] = 'your_key_here'"
        )

def build_chain():
    parser = PydanticOutputParser(pydantic_object=ResearchBrief)

    system_rules = (
        "You write ultra-concise, practical research briefs.\n"
        "Return ONLY JSON that matches this schema:\n{format_instructions}\n"
        "Rules:\n"
        "- Keep 'problem_statement' to <= 2 sentences.\n"
        "- 'key_questions' has 1–3 items.\n"
        "- 'method_brief' has 2–4 items.\n"
        "- 'deliverables' has 2–3 items.\n"
        "No markdown, no extra keys, no commentary."
    )

    prompt = (
        ChatPromptTemplate
        .from_messages([
            ("system", system_rules),
            ("human", "Topic: {topic}")
        ])
        .partial(format_instructions=parser.get_format_instructions())
    )

    model = ChatGoogleGenerativeAI(
        model="gemini-1.5-flash",
        temperature=0,
        max_retries=2,
    )

    return prompt | model | parser

def to_markdown(brief: ResearchBrief) -> str:
    lines = []
    lines.append(f"# {brief.title}")
    lines.append(f"**Problem:** {brief.problem_statement}")
    lines.append("**Key Questions:**")
    lines.extend(f"- {q}" for q in brief.key_questions)
    lines.append("**Method (brief):**")
    lines.extend(f"- {m}" for m in brief.method_brief)
    lines.append("**Deliverables:**")
    lines.extend(f"- {d}" for d in brief.deliverables)
    return "\n".join(lines)

require_api_key()
topic = input("Enter a research topic: ").strip()

if not topic:
    print("ERROR: Topic cannot be empty.", file=sys.stderr)
else:
    try:
        chain = build_chain()
        brief: ResearchBrief = chain.invoke({"topic": topic})

        print("\n JSON Output:")
        print(brief.model_dump_json(indent=2, ensure_ascii=False))

    except ValidationError as ve:
        print("ERROR: Model returned invalid JSON.", file=sys.stderr)
        print(ve, file=sys.stderr)
    except Exception as e:
        print(f"ERROR: {e}", file=sys.stderr)

import json

result = chain.invoke({"topic": topic})

# JSON Output
json_output = json.dumps(result.model_dump(), indent=2, ensure_ascii=False)
print("JSON Output:")
print(json_output)

# Markdown Output
md_output = to_markdown(result)

print("\nMarkdown Output:")
print(md_output)